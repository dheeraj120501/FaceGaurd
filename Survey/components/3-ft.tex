\section{Face Tracking} \label{section:ft}
A face tracker is a computer vision system or algorithm designed to locate and follow a face in a sequence of frames or a video stream. The primary goal of face tracking is to maintain the identity of a face over time, regardless of facial movements, rotations, occlusions, or changes in facial expressions. Several technologies and algorithms, ranging from classical computer vision techniques to deep learning models, can be used in face tracking. A comprehensive survey of Siamese trackers in visual object tracking (a parent field of face tracking) was done by Milan Ondrasovic et al \cite{ondrasovic_siamese_2021}. Siamese trackers leverage deep learning and similarity learning for tracking objects in videos. They tackle challenges like scale and lighting variations, occlusion, and background clutter. According to authors recent trends involve using deeper backbones like ResNet \cite{aziz_exploring_2020}, multi-level feature fusion, and template updating strategies for improved performance. Cross-correlation with attention mechanisms has shown promise in achieving a balance between speed and accuracy.

Kim et al. \cite{kim_facial_2023} while developing a real time face recognition system used deepSORT as the tracking module. SORT (Simple Online and Realtime Tracking) is to provide a computationally efficient and straightforward method for tracking objects, especially in real-time scenarios. While SORT is computationally efficient and suitable for real-time scenarios, it's primarily designed for scenarios where the number of objects remains relatively constant, and there are minimal interactions or occlusions among objects. For more complex scenarios with numerous occlusions, interactions, and variable object counts, more sophisticated algorithms like DeepSORT (which augments SORT with deep learning-based features).

Multi-face tracking in unconstrained videos to identify and maintain the identities of multiple faces over time is important in real time face recognition system. An online multi-face tracking method was proposed in \cite{weng_online_2023} introduces a two-stage structure: detection alignment and detection association. It aligns face detections with body detections and matches these aligned detections with face or body features to form tracking trajectories. Experiments on benchmark databases demonstrate that utilizing both face and body information significantly enhances tracking performance compared to using only face data, making it competitive with or superior to other online tracking methods for multi-face tracking. Another approach introduces a cross-camera multi-face tracking system for video surveillance \cite{ren_cross-camera_2021}. It combines the Chinese Whisper face clustering algorithm and Double Triplet Networks (DTN) to accurately track pedestrians' faces across different cameras. Experimental results demonstrate its effectiveness, achieving a recognition accuracy of 99.51\% with the DTN MSML Batch OHNM Subspace FOCAL LOSS model. It addresses challenges like small target tracking and occlusion, offering a robust solution for efficient face tracking in surveillance scenarios.

Face tracking in crowded scenes presents a myriad of challenges, central to which is the issue of occlusions where faces are frequently obscured by other individuals or objects. Such environments often result in overlapping faces, making distinct identification and continuous tracking a daunting task. Authors in \cite{barquero_rank-based_2021} focused on enhancing video surveillance systems in crowded and unconstrained scenarios and introduces a novel tracklet reconnection strategy, utilizing rank-based face verification, to extend track lengths by up to 50\% compared to deep learning trackers. This constraint method also reduces identity mixing errors and improves completion rates.

The issues of video face clustering in the context of increasing facial appearance diversity was addressed by Vivek sharma et al. \cite{sharma_video_2020}. They introduced unsupervised methods for feature refinement using deep pre-trained face networks and self-supervised Siamese networks. Discriminative models like Track-supervised Siamese Network (TSiam) and Self-supervised Siamese Network (SSiam) are proposed alongside Variational Autoencoders (VAEs) as a strong generative model baseline. The methods are evaluated on challenging video face clustering datasets and outperform existing state-of-the-art techniques. According to authors the models are computationally efficient, making them suitable for diverse appearance datasets.