\section{Face Tracking} \label{section:ft}
A face tracker is a computer vision system or algorithm designed to locate and follow a face in a sequence of frames or a video stream. The primary goal of face tracking is to maintain the identity of a face over time, regardless of facial movements, rotations, occlusions, or changes in facial expressions. Several technologies and algorithms, ranging from classical computer vision techniques to deep learning models, can be used in face tracking. A comprehensive survey of Siamese trackers in visual object tracking (a parent field of face tracking) was done by Milan Ondrasovic et al \cite{ondrasovic_siamese_2021}. Siamese trackers leverage deep learning and similarity learning for tracking objects in videos. They tackle challenges like scale and lighting variations, occlusion, and background clutter. According to authors recent trends involve using deeper backbones like ResNet \cite{aziz_exploring_2020}, multi-level feature fusion, and template updating strategies for improved performance. Cross-correlation with attention mechanisms has shown promise in achieving a balance between speed and accuracy.

Kim et al. \cite{kim_facial_2023} while developing a real time face recognition system used deepSORT as the tracking module. SORT (Simple Online and Realtime Tracking) is to provide a computationally efficient and straightforward method for tracking objects, especially in real-time scenarios. While SORT is computationally efficient and suitable for real-time scenarios, it's primarily designed for scenarios where the number of objects remains relatively constant, and there are minimal interactions or occlusions among objects. For more complex scenarios with numerous occlusions, interactions, and variable object counts, more sophisticated algorithms like DeepSORT (which augments SORT with deep learning-based features).

In real-time face recognition systems, multi-face tracking in unconstrained films is crucial for identifying and preserving the identities of numerous faces throughout time. \cite{weng_online_2023} presented a two-stage framework for an online multi-face tracking approach that includes detection alignment and detection association. To create tracking trajectories, it aligns face and body detections and compares the matched detections with characteristics found on the face or body. Trials on reference datasets show that tracking performance is much improved by combining both body and face information as opposed to only face data, which puts it on par with or better than previous online tracking techniques for multi-face tracking. An alternative method for video surveillance presents a cross-camera multi-face tracking system \cite{ren_cross-camera_2021}. It combines the Chinese Whisper face clustering algorithm and Double Triplet Networks (DTN) to accurately track pedestrians' faces across different cameras. Experimental results demonstrate its effectiveness, achieving a recognition accuracy of 99.51\% with the DTN MSML Batch OHNM Subspace FOCAL LOSS model. It addresses challenges like small target tracking and occlusion, offering a robust solution for efficient face tracking in surveillance scenarios.

Face tracking in crowded scenes presents a myriad of challenges, central to which is the issue of occlusions where faces are frequently obscured by other individuals or objects. Such environments often result in overlapping faces, making distinct identification and continuous tracking a daunting task. Authors in \cite{barquero_rank-based_2021} focused on enhancing video surveillance systems in crowded and unconstrained scenarios and introduces a novel tracklet reconnection strategy, utilizing rank-based face verification, to extend track lengths by up to 50\% compared to deep learning trackers. This constraint method also reduces identity mixing errors and improves completion rates.

Vivek Sharma et al. \cite{sharma_video_2020} tackled the problems of video face clustering in the context of growing variety in facial appearance. They presented self-supervised Siamese networks and deep pre-trained face networks as unsupervised techniques for feature refining. As a robust generative model baseline, discriminative models such as Track-supervised Siamese Network (TSiam) and Self-supervised Siamese Network (SSiam) are suggested in conjunction with Variational Autoencoders (VAEs). The algorithms outperform current state-of-the-art techniques when tested on difficult video face clustering datasets. The models' computational efficiency, according to the authors, makes them appropriate for a variety of appearance datasets.