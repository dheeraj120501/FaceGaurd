\section{Face Recognition} \label{section:fr}
Facial recognition systems generally follow a three-step approach: face detection \ref{section:fd}, face tracking \ref{section:ft}, feature extraction, and identification or verification. While deep learning techniques have significantly improved facial recognition performance, achieving accuracy rates over 99\% on certain datasets, there are concerns about their real-world applicability, especially when recognizing individuals intent on avoiding detection \cite{kim_surveillance_2023}.

Face recognition starts with extracting the face area and its features, which can be a classification challenge to determine if the detected section is a face.

Facial recognition in videos can present ethical dilemmas, particularly in mistakenly identifying innocent bystanders. Most surveillance cameras record at 15 FPS due to storage constraints, but can capture at faster rates. Videos, which provide higher-dimensional data than static images, often give fragmented insights.

Authors in \cite{zhu_webface260m_2023} presents WebFace260M benchmark dataset, WebFace42M benchmark dataset and the Face Recognition Under Inference Time conStraint (FRUITS) protocol for comprehensive evaluation and addresses biased face recognition deployments, including masked and unbiased scenarios. 

Kim et al. \cite{kim_facial_2023} proposed a real-time Criminal Recognition system with 2 major update one is down sampling the input image for reducing the latency during the face detection, whereas high identification accuracy is maintained during the identification step by cropping the face regions from the original high-resolution images. Other update was introduction of Score Dictionary Identification where scores related to the identification results are accumulated for the face ID of each tracked face by creating a dictionary with the tracking ID as a key. The dictionary monitors the score such that when the score exceeds an arbitrary threshold, the system notifies parties of the identification result and transmits the appearance of the criminal.

\subsection{For Devices with limited Computational Power}

Alansari et al. \cite{alansari_ghostfacenets_2023} proposed a deep learning biometric models suitable for devices with limited memory and computational power by the introduction of Ghost modules marks a significant advancement. The model was named GhostFaceNets, lightweight face recognition models, are built upon GhostNetV1 and GhostNetV2, both rooted in Ghost modules. GhostFaceNets, when trained using the ArcFace loss on the refined MS-Celeb-1M dataset, showcased leading performance across benchmarks. They significantly boost efficiency in face verification compared to earlier top mobile CNNs. GhostFaceNets greatly improve efficiency for face verification tasks compared to previous SOTA mobile CNNs, making them suitable for deployment on devices with constrained memory and computational resources. In another such paper \cite{abuzneid_enhanced_2018} authors used back-propagation neural network (BPNN) and correlation-based feature extraction to improve face recognition accuracy. The proposed method achieves higher accuracy with reduced computational cost by generating a new set called the T-Dataset and using a local binary pattern histogram descriptor.

\subsection{Homogeneous Face Recognition}

Homogeneous Face Recognition generally refers to scenarios where the recognition system is designed to handle specific variations or challenges, such as age, pose, lighting, or expression.

With the advent of Covid-19 pandemic a new challenge for face recognition arise which was Masked Face Recognition. Given the global health circumstances since 2020 and the widespread adoption of face masks, masked face recognition has become a notable subfield within Homogeneous Face Recognition, addressing the unique challenges introduced by facial coverings.A masked face recognition algorithm with the combination of Convolutional Neural Network (CNN) and Support Vector Machine (SVM) was proposed by authors in \cite{9914874} where CNN is implemented to train the model, while SVM is used as a label classification method. Two benchmarked datasets, the Real World Masked Face Dataset (RMFD) and the Labelled Face in The Wild Simulated Masked Face Dataset (LFW-SMFD), are used in the experiments. The proposed method achieves a 98.39 percent true acceptance rate on RMFD and 94.29 percent on LFW-SMFD, demonstrating its practicality in recognizing unconstrained face images. Pedro Neto et al. \cite{pedro_neto_beyond_2022} accessed the performance of MFR algorithms was assessed on both masked and occluded face datasets. This assessment was again repeated using a top-performing occluded face recognition algorithm. Finally, to understand the broader context, the evaluation was again performed using algorithms intended for general face recognition. The authors evaluate several approaches for handling masks, including unmasking the input image, unmasking the template generated by a face recognition model, and using a model that is robust to masks.

Age significantly impacts face recognition due to the natural morphological changes that occur over time. Age-related factors can introduce intra-class variations that may pose challenges to recognition algorithms. Age-Invariant Model (AIM) \cite{zhao_towards_2022} was proposed for face recognition in the wild. The model performs cross-age face synthesis and recognition jointly. The AIM model achieves continuous face rejuvenation/aging with photorealistic and identity-preserving properties, without the need for paired data or the true age of testing samples.

\subsection{Heterogeneous Face Recognition}

One other field of face recognition is Heterogeneous Face Recognition (HFR) which refers to the task of matching faces across different domains or modalities. It involves matching a near-infrared (NIR) facial image with a visible light facial image, a sketch of a face with a photographic image, or a thermal image of a face with a regular visible spectrum image etc. A Dual variational generation (DVG-Face) \cite{fu_dvg-face_2022} framework to tackle the heterogeneous face recognition (HFR) problem. It formulates HFR as a dual generation problem and designs a dual variational generator to learn the joint distribution of paired heterogeneous images. A pairwise identity preserving loss is imposed on the generated paired heterogeneous images to ensure their identity consistency. The generated paired heterogeneous images are used to train the HFR network via a contrastive learning mechanism, which yields both domain-invariant and discriminative embedding features. DVG-Face outperforms state-of-the-art methods on seven challenging databases belonging to five HFR tasks, including NIR-VIS, Sketch-Photo, Profile-Frontal Photo, Thermal-VIS, and ID-Camera.
Decheng Liu et al. \cite{liu_heterogeneous_2022} proposed approach with three components, a Graph Convolutional Autoencoder (GCA) for encoding 3D faces into latent representations, a Generative Adversarial Network (GAN) for translating the latent representations of expressive faces into those of neutral faces, and an identity recognition sub-network that utilizes the neutralized latent representations for 3D face recognition. This has practical implications in the field of 3D face recognition and expression neutralization. It offers a method to generate realistic 3D faces with neutral expressions while predicting their identities.
Face Synthesis with Identity-Attribute Disentanglement (FSIAD) \cite{yang_heterogeneous_2022} for Heterogeneous Face Recognition involves two main steps: identity-attribute disentanglement (IAD) and face synthesis module (FSM). Face images are separated into identity-related representations and identity-unrelated representations (attributes) to decrease the correlation between identities and attributes in the IAD step and the FSM is then used to generate a large number of images with stochastic combinations of disentangled identities and attributes, enriching the attribute diversity of synthetic images.
