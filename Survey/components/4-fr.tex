\section{Face Recognition} \label{section:fr}
Facial recognition systems generally follow a three-step approach: face detection \ref{section:fd}, face tracking \ref{section:ft}, feature extraction, and identification or verification. While deep learning techniques have significantly improved facial recognition performance, achieving accuracy rates over 99\% on certain datasets, there are concerns about their real-world applicability, especially when recognizing individuals intent on avoiding detection \cite{kim_surveillance_2023}.

Face recognition starts with extracting the face area and its features, which can be a classification challenge to determine if the detected section is a face.

Facial recognition in videos can present ethical dilemmas, particularly in mistakenly identifying innocent bystanders. Most surveillance cameras record at 15 FPS due to storage constraints, but can capture at faster rates. Videos, which provide higher-dimensional data than static images, often give fragmented insights.

Authors in \cite{zhu_webface260m_2023} presents WebFace260M benchmark dataset, WebFace42M benchmark dataset and the Face Recognition Under Inference Time conStraint (FRUITS) protocol for comprehensive evaluation and addresses biased face recognition deployments, including masked and unbiased scenarios. 

Kim et al. \cite{kim_facial_2023} proposed a real-time Criminal Recognition system with 2 major update one is down sampling the input image for reducing the latency during the face detection, whereas high identification accuracy is maintained during the identification step by cropping the face regions from the original high-resolution images. The addition of Score Dictionary Identification was another improvement. This method involves building a dictionary using the tracking ID as a key and adding scores relevant to the identification results for each monitored face's face ID. The dictionary keeps track of the score so that when it rises beyond a certain level, the system sends out an identification result and the criminal's picture.

\subsection{For Devices with limited Computational Power}

Alansari et al. \cite{alansari_ghostfacenets_2023} proposed a deep learning biometric models suitable for devices with limited memory and computational power by the introduction of Ghost modules marks a significant advancement. The model was named GhostFaceNets, lightweight face recognition models, are built upon GhostNetV1 and GhostNetV2, both rooted in Ghost modules. GhostFaceNets, when trained using the ArcFace loss on the refined MS-Celeb-1M dataset, showcased leading performance across benchmarks. They significantly boost efficiency in face verification compared to earlier top mobile CNNs. GhostFaceNets greatly improve efficiency for face verification tasks compared to previous SOTA mobile CNNs, making them suitable for deployment on devices with constrained memory and computational resources. In another such paper \cite{abuzneid_enhanced_2018} authors used back-propagation neural network (BPNN) and correlation-based feature extraction to improve face recognition accuracy. The proposed method achieves higher accuracy with reduced computational cost by generating a new set called the T-Dataset and using a local binary pattern histogram descriptor.

\subsection{Homogeneous Face Recognition}

Homogeneous Face Recognition generally refers to scenarios where the recognition system is designed to handle specific variations or challenges, such as age, pose, lighting, or expression.

With the advent of Covid-19 pandemic a new challenge for face recognition arise which was Masked Face Recognition. Given the global health circumstances since 2020 and the widespread adoption of face masks, masked face recognition has become a notable subfield within Homogeneous Face Recognition, addressing the unique challenges introduced by facial coverings.The authors \cite{9914874} suggested a masked facial recognition algorithm that combines Support Vector Machine (SVM) and Convolutional Neural Network (CNN): SVM is used as a label classification technique, while CNN is utilised to train the model. The studies employ two benchmarked datasets: the Labelled Face in The Wild Simulated Masked Face Dataset (LFW-SMFD) and the Real World Masked Face Dataset (RMFD). The suggested approach shows promise in identifying unconstrained face photos with a 98.39 percent true acceptance rate on RMFD and 94.29 percent on LFW-SMFD. Pedro Neto et al. \cite{pedro_neto_beyond_2022} accessed the performance of MFR algorithms was assessed on both masked and occluded face datasets. This assessment was again repeated using a top-performing occluded face recognition algorithm. Finally, to understand the broader context, the evaluation was again performed using algorithms intended for general face recognition. The authors evaluate several approaches for handling masks, including unmasking the input image, unmasking the template generated by a face recognition model, and using a model that is robust to masks.

Age significantly impacts face recognition due to the natural morphological changes that occur over time. Age-related factors can introduce intra-class variations that may pose challenges to recognition algorithms. Age-Invariant Model (AIM) \cite{zhao_towards_2022} was proposed for face recognition in the wild. The model performs cross-age face synthesis and recognition jointly. The AIM model achieves continuous face rejuvenation/aging with photorealistic and identity-preserving properties, without the need for paired data or the true age of testing samples.

\subsection{Heterogeneous Face Recognition}

One other field of face recognition is Heterogeneous Face Recognition (HFR) which refers to the task of matching faces across different domains or modalities. It involves matching a near-infrared (NIR) facial image with a visible light facial image, a sketch of a face with a photographic image, or a thermal image of a face with a regular visible spectrum image etc. To address the heterogeneous facial recognition (HFR) challenge, a Dual variational generation (DVG-facial) \cite{fu_dvg-face_2022} framework is used. It uses a dual variational generator to learn the joint distribution of paired heterogeneous pictures and formulates HFR as a dual generation issue. To guarantee the identity consistency of the resulting paired heterogeneous pictures, a pairwise identity preservation loss is applied to them. The HFR network is trained using the produced paired heterogeneous pictures using a contrastive learning method, producing both discriminative and domain-invariant embedding features. On seven difficult datasets from five HFR tasks (NIR-VIS, Sketch-Photo, Profile-Frontal Photo, Thermal-VIS, and ID-Camera), DVG-Face beats the state-of-the-art techniques.
Graph Convolutional Autoencoder (GCA) for encoding 3D faces into latent representations, Generative Adversarial Network (GAN) for converting expressive faces' latent representations into neutral faces' latent representations, and identity recognition sub-network for 3D face recognition using the neutralised latent representations are the three components of the approach proposed by Decheng Liu et al. \cite{liu_heterogeneous_2022}. In the areas of 3D facial recognition and expression neutralisation, this has real-world applications. It provides a way to anticipate the identities of characters and produce realistic 3D faces with neutral emotions.
For Heterogeneous Face Synthesis, Identity-Attribute Disentanglement (FSIAD) \cite{yang_heterogeneous_2022} Identity-attribute disentanglement (IAD) and the face synthesis module (FSM) are the two primary phases in face recognition. In order to reduce the correlation between identities and attributes, face images are divided into identity-related representations and identity-unrelated representations (attributes) in the IAD step. The FSM is then used to generate a large number of images with stochastic combinations of identities and attributes that have been disentangled, enhancing the attribute diversity of synthetic images.
